# -*- coding: utf-8 -*-
"""house_prices.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1axk9J-Mf4cMVk5OYvfvWFmN_zyYOVEIQ
"""

!pip install -q scikit-learn pandas matplotlib seaborn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import SelectFromModel
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import mean_squared_error, r2_score

from google.colab import files
uploaded = files.upload()  # Upload 'train.csv'

df = pd.read_csv("train.csv")
df.head()

df.info()
df.describe()
df.isnull().sum().sort_values(ascending=False)

sns.scatterplot(x=df['GrLivArea'], y=df['SalePrice'])

sns.barplot(x='Neighborhood', y='SalePrice', data=df)

sns.boxplot(x=df['OverallQual'], y=df['SalePrice'])

# Drop columns with too many missing values
df = df.dropna(thresh=len(df) * 0.7, axis=1)

# Drop ID column
df.drop(columns=["Id"], inplace=True)

# Separate target
X = df.drop("SalePrice", axis=1)
y = df["SalePrice"]

# Column types
num_cols = X.select_dtypes(include=["int64", "float64"]).columns.tolist()
cat_cols = X.select_dtypes(include=["object"]).columns.tolist()

# Pipelines
num_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

cat_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

# Full preprocessor
preprocessor = ColumnTransformer([
    ("num", num_pipeline, num_cols),
    ("cat", cat_pipeline, cat_cols)
])

# Fit and transform the features
X_processed = preprocessor.fit_transform(X)

# Confirm shape
print("Processed feature shape:", X_processed.shape)

# PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_processed)

plt.figure(figsize=(8, 6))
plt.title("PCA Visualization")
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', s=10)
plt.colorbar(label="SalePrice")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.tight_layout()
plt.show()

# t-SNE
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_tsne = tsne.fit_transform(X_processed)

plt.figure(figsize=(8, 6))
plt.title("t-SNE Visualization")
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='plasma', s=10)
plt.colorbar(label="SalePrice")
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.tight_layout()
plt.show()

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)

# Model and param search
model = RandomForestRegressor(random_state=42)
param_grid = {
    "n_estimators": [100, 200, 300],
    "max_depth": [10, 20, 30, None],
    "min_samples_split": [2, 5, 10]
}

search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=3,
                            scoring="neg_mean_squared_error", random_state=42)
search.fit(X_train, y_train)
best_model = search.best_estimator_

# Predictions & metrics
y_pred = best_model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"R² Score: {r2:.4f}")

# ridge Regression
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

ridge = Ridge(alpha=1.0)  # Tune alpha
ridge.fit(X_train, y_train)

y_pred_ridge = ridge.predict(X_test)

print("Ridge RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))
print("Ridge R²:", r2_score(y_test, y_pred_ridge))

#lasso regression
from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.01, max_iter=10000)  # alpha needs tuning
lasso.fit(X_train, y_train)

y_pred_lasso = lasso.predict(X_test)

print("Lasso RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lasso)))
print("Lasso R²:", r2_score(y_test, y_pred_lasso))